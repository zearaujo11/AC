{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of teams that will reach the Playoffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "! pip install tabulate\n",
    "from tabulate import tabulate\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "players = pd.read_csv('basketballPlayoffs/players.csv', delimiter=\",\")\n",
    "coaches = pd.read_csv('basketballPlayoffs/coaches.csv', delimiter=\",\")\n",
    "teams = pd.read_csv('basketballPlayoffs/teams.csv', delimiter=\",\")\n",
    "players_teams = pd.read_csv('basketballPlayoffs/players_teams.csv', delimiter=\",\")\n",
    "teams_post = pd.read_csv('basketballPlayoffs/teams_post.csv', delimiter=\",\")\n",
    "series_post = pd.read_csv('basketballPlayoffs/series_post.csv', delimiter=\",\")\n",
    "awards_players = pd.read_csv('basketballPlayoffs/awards_players.csv', delimiter=\",\")\n",
    "awards_coaches = pd.read_csv('basketballPlayoffs/awards_coaches.csv', delimiter=\",\")\n",
    "\n",
    "print(players.head())\n",
    "print(coaches)\n",
    "print(teams)\n",
    "print(players_teams)\n",
    "print(teams_post)\n",
    "print(series_post)\n",
    "print(awards_players)\n",
    "print(awards_coaches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for missing values, outliers, and inconsistencies in the data. Clean and preprocess the data to ensure it's ready for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teams dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(teams.isna().sum())\n",
    "print(teams.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Players Teams dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(players_teams.isna().sum())\n",
    "print(players_teams.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Players dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(players.isna().sum())\n",
    "print(players.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coaches dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coaches.isna().sum())\n",
    "print(coaches.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Awards Players dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(awards_players.isna().sum())\n",
    "print(awards_players.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Awards Coaches dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(awards_coaches.isna().sum())\n",
    "print(awards_coaches.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conduct EDA to gain insights into the data. Visualize distributions, correlations, and patterns. This step will help you understand the relationships between different features and the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teams metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams.head()\n",
    "\n",
    "teams.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in teams.columns:\n",
    "    unique_values = teams[column].unique()\n",
    "    print(f\"Number of different values in the {column} column are:\", len(unique_values))\n",
    "    print(\"------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = []\n",
    "value_counts = []\n",
    "\n",
    "for column in teams.columns:\n",
    "    unique_values = teams[column].nunique()\n",
    "    columns.append(column)\n",
    "    value_counts.append(unique_values)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.barh(columns, value_counts, color='skyblue')\n",
    "plt.xlabel('Number of Unique Values')\n",
    "plt.ylabel('Columns')\n",
    "plt.title('Number of Unique Values in Each Column')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(teams.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_numeric = teams.copy()\n",
    "\n",
    "for column in teams_numeric.columns:\n",
    "    if teams_numeric[column].dtype == 'object':\n",
    "        teams_numeric[column] = teams_numeric[column].astype('category').cat.codes\n",
    "\n",
    "teams_numeric.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_matrix(dataframe):\n",
    "    corr_matrix = dataframe.corr()\n",
    "\n",
    "    target_correlation = corr_matrix['playoff']\n",
    "\n",
    "    plt.figure(figsize=(30, 20))\n",
    "\n",
    "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "\n",
    "    sns.heatmap(corr_matrix, mask=mask, annot=True, annot_kws={\"size\": 8}, cmap='coolwarm', linewidths=0.5, fmt=\".2f\")\n",
    "\n",
    "    plt.title('Correlation Matrix', fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "    dict = {}\n",
    "\n",
    "    for feature, correlation in target_correlation.items():\n",
    "        print(f\"Correlation between target and {feature}: {correlation}\")\n",
    "        dict[feature] = correlation\n",
    "\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix(teams_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_square(dataset, target): \n",
    "    for feature in dataset.columns:\n",
    "        if feature != target:\n",
    "            contingency_table = pd.crosstab(dataset[feature], dataset[target])\n",
    "\n",
    "            # check if any category has no data\n",
    "            if contingency_table.shape[0] == 0 or contingency_table.shape[1] == 0:\n",
    "                print(f\"No data for {feature} and {target}\")\n",
    "                continue\n",
    "            \n",
    "            chi2, p, observed, expected = chi2_contingency(contingency_table)\n",
    "            \n",
    "            # Step 4: Print or store the results\n",
    "            print(f\"Chi-square test for {feature} and {target}:\")\n",
    "            print(f\"Chi-square value: {chi2}\")\n",
    "            print(f\"P-value: {p}\")\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_square(teams, 'playoff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value indicates the probability of observing a relationship as extreme as the one in our sample data, assuming that there is no actual relationship in the population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Players metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(players['playerID'].nunique()) \n",
    "\n",
    "print(players.head())\n",
    "\n",
    "players.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erased columns and why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropped columns: 'collegeOther', 'deathDate', 'firstseason', 'lastseason'\n",
    "\n",
    "# Count the rows where 'firstseason' is not equal to 0\n",
    "non_zero_firstseason_count = len(players[players['firstseason'] != 0])\n",
    "\n",
    "# Count the rows where 'firstseason' is not equal to 0\n",
    "non_zero_lastseason_count = len(players[players['lastseason'] != 0])\n",
    "\n",
    "# Count the rows where 'deathDate' is not equal to \"0000-00-00\"\n",
    "players['deathDate'] = players['deathDate'].str.strip()\n",
    "non_empty_deathDate_count = len(players[players['deathDate'] != \"0000-00-00\"])\n",
    "\n",
    "# Count the rows where 'collegeOther' is not equal to \"\"\n",
    "non_nan_collegeOther_count = players['collegeOther'].notna().sum()\n",
    "\n",
    "print(\"Number of rows with 'firstseason' different from 0:\", non_zero_firstseason_count)\n",
    "print(\"Number of rows with 'lastseason' different from 0:\", non_zero_lastseason_count)\n",
    "print(\"Number of rows with 'collegeOther' different from \"\":\", non_nan_collegeOther_count)\n",
    "print(\"Number of rows with 'deathDate' different from '0000-00-00':\", non_empty_deathDate_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Players heights comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert height from inches to centimeters\n",
    "players['height_cm'] = players['height'] * 2.54  # 1 inch = 2.54 cm\n",
    "\n",
    "# Define height categories in centimeters\n",
    "height_categories = ['< 160.0 cm', '160.0 - 170.0 cm', '170.0 - 180.0 cm', '180.0 - 190.0 cm', '190.0 - 200.0 cm', '> 200.0 cm']\n",
    "\n",
    "# Define the height ranges for each category\n",
    "height_ranges = [(0, 160.0), (160.0, 170.0), (170.0, 180.0), (180.0, 190.0), (190.0, 200.0), (200.0, float('inf'))]\n",
    "\n",
    "# Create a new column in the dataset to store the height category for each player\n",
    "players['height_category'] = pd.cut(players['height_cm'], bins=[r[0] for r in height_ranges] + [float('inf')], labels=height_categories)\n",
    "\n",
    "# Count the number of players in each height category\n",
    "height_category_counts = players['height_category'].value_counts().reindex(height_categories, fill_value=0)\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(x=height_category_counts.index, y=height_category_counts.values, palette='Set2')\n",
    "\n",
    "# Add labels to the bars\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', fontsize=10, color='black', xytext=(0, 5), textcoords='offset points')\n",
    "\n",
    "# Set plot title and labels\n",
    "plt.title('Player Count in Height Categories')\n",
    "plt.xlabel('Height Category')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of players in each position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a countplot for player positions\n",
    "plt.figure(figsize=(10, 6))  # Adjust the figure size as needed\n",
    "ax = sns.countplot(data=players, x='pos', order=players['pos'].value_counts().index, palette='Set2')\n",
    "\n",
    "# Add labels to the bars\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', fontsize=10, color='black', xytext=(0, 5), textcoords='offset points')\n",
    "\n",
    "# Set plot title and labels\n",
    "plt.title('Number of Players in Each Position')\n",
    "plt.xlabel('Position')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Rotate x-axis labels for better readability (optional)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "empty_pos_count = players['pos'].isnull().sum()\n",
    "print(\"Number of rows with empty 'pos':\", empty_pos_count)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 Colleges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 10 colleges with the most players\n",
    "top_10_colleges = players['college'].value_counts().iloc[:10]\n",
    "\n",
    "# Create a countplot for the top 10 colleges\n",
    "plt.figure(figsize=(12, 6))  # Adjust the figure size as needed\n",
    "ax = sns.countplot(data=players, x='college', order=top_10_colleges.index, palette='Set2')\n",
    "\n",
    "# Add labels to the bars\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', fontsize=10, color='black', xytext=(0, 5), textcoords='offset points')\n",
    "\n",
    "# Set plot title and labels\n",
    "plt.title('Top 10 Colleges with the Most Players')\n",
    "plt.xlabel('College')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Rotate x-axis labels for better readability (optional)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Matrix between numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns for correlation analysis\n",
    "numeric_columns = [\"firstseason\", \"lastseason\", \"height\", \"weight\"]\n",
    "\n",
    "# Create a subset of the dataset with only the numeric columns\n",
    "subset = players[numeric_columns]\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "corr_matrix = subset.corr()\n",
    "\n",
    "# Create a heatmap of the correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teams Post metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(teams_post.head())\n",
    "\n",
    "teams_post.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate win-loss ratios\n",
    "teams_post['Win-Loss Ratio'] = teams_post['W'] / (teams_post['W'] + teams_post['L'])\n",
    "\n",
    "# Create a horizontal bar chart\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(teams_post['tmID'], teams_post['Win-Loss Ratio'], color='skyblue')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Win-Loss Ratio')\n",
    "plt.ylabel('Team ID (tmID)')\n",
    "plt.title('Win-Loss Ratios for Teams on  Post-Season (based on tmID)')\n",
    "\n",
    "# Show the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series Post metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by year and count the number of wins for each team in each year\n",
    "team_wins_by_year = series_post.groupby(['year', 'tmIDWinner'])['W'].count().unstack(fill_value=0)\n",
    "\n",
    "# Create a stacked bar chart\n",
    "plt.figure(figsize=(12, 8))\n",
    "team_wins_by_year.plot(kind='bar', stacked=True, colormap='Set3')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Wins')\n",
    "plt.title('Teams That Won In The Playoffs Each Year')\n",
    "\n",
    "# Show the chart\n",
    "plt.legend(title='Team', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Teams that won and lost each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for the \"F\" (Finals) round\n",
    "finals_data = series_post[series_post['round'] == 'F']\n",
    "\n",
    "# Create a DataFrame with the winning and losing teams for each year\n",
    "finals_results = finals_data[['year', 'tmIDWinner', 'tmIDLoser']]\n",
    "\n",
    "# Convert the DataFrame to a prettily formatted table\n",
    "table = tabulate(finals_results, headers='keys', tablefmt='fancy_grid', showindex=False)\n",
    "\n",
    "# Display the formatted table\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for the \"F\" (Finals) round\n",
    "finals_data = series_post[series_post['round'] == 'F']\n",
    "\n",
    "# Count how many times each team has appeared in the Finals as either a winner or a loser\n",
    "team_appearances = pd.concat([finals_data['tmIDWinner'], finals_data['tmIDLoser']]).value_counts()\n",
    "\n",
    "# Create a horizontal bar chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "team_appearances.plot(kind='barh', color='skyblue')\n",
    "\n",
    "# Add labels and title\n",
    "plt.ylabel('Team (tmID)')\n",
    "plt.xlabel('Number of Finals Appearances')\n",
    "plt.title('Total Appearances of Each Team in the Finals')\n",
    "\n",
    "# Show the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coaches metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coaches['coachID'].nunique()) \n",
    "\n",
    "print(coaches.head())\n",
    "\n",
    "coaches.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the wins and losses data from the \"won\" and \"lost\" columns\n",
    "coach_wins = coaches['won']\n",
    "coach_losses = coaches['lost']\n",
    "\n",
    "# Create a scatter plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(coach_wins, coach_losses, alpha=0.5)\n",
    "plt.xlabel('Wins')\n",
    "plt.ylabel('Losses')\n",
    "plt.title('Scatter Plot of Coach Wins vs. Losses')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify and select relevant features for your prediction model. Use techniques such as correlation analysis, recursive feature elimination, or feature importance from tree-based models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teams dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_teams = teams.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to delete: lgID, divID, seeded, tmORB, tmDRB, tmTRB, opptmORB, opptmDRB, opptmTRB, rank, firstRound, semis, finals\n",
    "print(teams.isna().sum())\n",
    "   \n",
    "feature_selection_result = teams.drop(columns=['lgID', 'divID', 'seeded', 'tmORB', 'tmDRB', 'tmTRB', 'opptmORB', 'opptmDRB', 'opptmTRB'])\n",
    "feature_selection_result = feature_selection_result.drop(columns=['rank', 'firstRound', 'semis', 'finals'])\n",
    "feature_selection_result = feature_selection_result.drop(columns=['min', 'o_oreb', 'o_dreb', 'd_oreb', 'd_dreb', 'name', 'franchID'])\n",
    "\n",
    "feature_selection_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection_result.to_csv('filtered/feature_selection_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new features that might enhance the predictive power of your model. This could involve transforming existing features, creating interaction terms, or incorporating external data.\n",
    "\n",
    "The feauture enginnering is done inside the `players.ipynb` file and the creation of the new dataset is done inside `create_final_team.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: verificar se pode ficar assim ou se adicionamos o código cá\n",
    "feature_engineering_result = pd.read_csv('filtered/feature_engineering_dataset.csv', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shifting target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_target_variable(dataset):\n",
    "    dataset.sort_values(by=['tmID', 'year'], inplace=True)\n",
    "\n",
    "    dataset['playoffs'] = dataset.groupby('tmID')['playoff'].shift(-1)\n",
    "\n",
    "    dataset.drop(columns=['playoff'], inplace=True)\n",
    "\n",
    "    dataset.dropna(subset=['playoffs'], inplace=True)\n",
    "\n",
    "    dataset.rename(columns={'playoffs': 'playoff'}, inplace=True)\n",
    "\n",
    "    dataset.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_teams = shift_target_variable(original_teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_teams_numeric = original_teams.copy()\n",
    "\n",
    "for column in original_teams_numeric.columns:\n",
    "    if original_teams_numeric[column].dtype == 'object':\n",
    "        original_teams_numeric[column] = original_teams_numeric[column].astype('category').cat.codes\n",
    "\n",
    "correlation_matrix(original_teams_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection_result = shift_target_variable(feature_selection_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_teams_numeric = feature_selection_result.copy()\n",
    "\n",
    "for column in feature_teams_numeric.columns:\n",
    "    if feature_teams_numeric[column].dtype == 'object':\n",
    "        feature_teams_numeric[column] = feature_teams_numeric[column].astype('category').cat.codes\n",
    "\n",
    "correlation_matrix(feature_teams_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature engineering dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng1_teams_numeric = shift_target_variable(feature_engineering_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng1_teams_numeric = eng1_teams_numeric.copy()\n",
    "\n",
    "for column in eng1_teams_numeric.columns:\n",
    "    if eng1_teams_numeric[column].dtype == 'object':\n",
    "        eng1_teams_numeric[column] = eng1_teams_numeric[column].astype('category').cat.codes\n",
    "\n",
    "correlation_matrix(eng1_teams_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_engineering_result2 = pd.read_csv('filtered/team2.csv', delimiter=\",\")\n",
    "feature_engineering_result2.drop(columns=['playoff'], inplace=True)\n",
    "\n",
    "feature_engineering_result2 = pd.merge(feature_engineering_result, feature_engineering_result2, on=['tmID', 'year'])\n",
    "\n",
    "feature_engineering_result2.to_csv('text.csv', index=False)\n",
    "\n",
    "feature_engineering_result2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng2_teams_numeric = feature_engineering_result2.copy()\n",
    "\n",
    "for column in eng2_teams_numeric.columns:\n",
    "    if eng2_teams_numeric[column].dtype == 'object':\n",
    "        eng2_teams_numeric[column] = eng2_teams_numeric[column].astype('category').cat.codes\n",
    "\n",
    "correlation_matrix(eng2_teams_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous = ['year', 'average_powerRanking', 'average_PER', 'average_postPowerRanking', 'average_postPER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng2_teams_numeric.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tmID, confID, playoff, arena\n",
    "# name, franchID, lgID, divID\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Apply label encoding to the columns 'teamID', 'franchID', 'confID', 'name', 'arena'\n",
    "original_teams['tmID'] = label_encoder.fit_transform(original_teams['tmID'])\n",
    "original_teams['confID'] = label_encoder.fit_transform(original_teams['confID'])\n",
    "original_teams['arena'] = label_encoder.fit_transform(original_teams['arena'])\n",
    "original_teams['name'] = label_encoder.fit_transform(original_teams['name'])\n",
    "original_teams['franchID'] = label_encoder.fit_transform(original_teams['franchID'])\n",
    "original_teams['lgID'] = label_encoder.fit_transform(original_teams['lgID'])\n",
    "original_teams['divID'] = label_encoder.fit_transform(original_teams['divID'])\n",
    "original_teams['firstRound'] = label_encoder.fit_transform(original_teams['firstRound'])\n",
    "original_teams['semis'] = label_encoder.fit_transform(original_teams['semis'])\n",
    "original_teams['finals'] = label_encoder.fit_transform(original_teams['finals'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection_result['tmID'] = label_encoder.fit_transform(feature_selection_result['tmID'])\n",
    "feature_selection_result['confID'] = label_encoder.fit_transform(feature_selection_result['confID'])\n",
    "feature_selection_result['arena'] = label_encoder.fit_transform(feature_selection_result['arena'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply label encoding to the columns 'teamID'\n",
    "feature_engineering_result['tmID'] = label_encoder.fit_transform(feature_engineering_result['tmID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_engineering_result2['tmID'] = label_encoder.fit_transform(feature_engineering_result2['tmID'])\n",
    "feature_engineering_result2['confID'] = label_encoder.fit_transform(feature_engineering_result2['confID'])\n",
    "feature_engineering_result2['arena'] = label_encoder.fit_transform(feature_engineering_result2['arena'])\n",
    "\"\"\" feature_engineering_result2['firstRound'] = label_encoder.fit_transform(feature_engineering_result2['firstRound'])\n",
    "feature_engineering_result2['semis'] = label_encoder.fit_transform(feature_engineering_result2['semis'])\n",
    "feature_engineering_result2['finals'] = label_encoder.fit_transform(feature_engineering_result2['finals']) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_model(dataset, year): \n",
    "    X_train = dataset[dataset['year'] < year].drop(columns=['playoff'])  \n",
    "    y_train = dataset[dataset['year'] < year]['playoff']\n",
    "\n",
    "    X_test = dataset[dataset['year'] == year].drop(columns=['playoff'])  \n",
    "    y_test = dataset[dataset['year'] == year]['playoff']\n",
    "\n",
    "    model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    \n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_model(original_teams, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Selection dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_model(feature_selection_result, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature engineering dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_model(feature_engineering_result, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_model(feature_engineering_result2, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_model(dataset, year): \n",
    "    X_train = dataset[dataset['year'] < year].drop(columns=['playoff'])\n",
    "    y_train = dataset[dataset['year'] < year]['playoff']\n",
    "\n",
    "    X_test = dataset[dataset['year'] == year].drop(columns=['playoff'])\n",
    "    y_test = dataset[dataset['year'] == year]['playoff']\n",
    "\n",
    "    rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "    accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "    print(f\"Random Forest Accuracy: {accuracy_rf:.2f}\")\n",
    "\n",
    "    print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_model(original_teams, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Selection dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_model(feature_selection_result, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature engineering dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_model(feature_engineering_result, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_model(feature_engineering_result2, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_model(dataset, year): \n",
    "    X_train = dataset[dataset['year'] < year].drop(columns=['playoff'])\n",
    "    y_train = dataset[dataset['year'] < year]['playoff']\n",
    "\n",
    "    X_test = dataset[dataset['year'] == year].drop(columns=['playoff'])\n",
    "    y_test = dataset[dataset['year'] == year]['playoff']\n",
    "\n",
    "    logreg_model = LogisticRegression(random_state=42)\n",
    "\n",
    "    logreg_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_logreg = logreg_model.predict(X_test)\n",
    "\n",
    "    accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n",
    "    print(f\"Logistic Regression Accuracy: {accuracy_logreg:.2f}\")\n",
    "\n",
    "    print(classification_report(y_test, y_pred_logreg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_model(original_teams, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Selection dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_model(feature_selection_result, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Engineering dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_model(feature_engineering_result, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_model(feature_engineering_result2, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_model(dataset, year): \n",
    "    X_train = dataset[dataset['year'] < year].drop(columns=['playoff'])\n",
    "    y_train = dataset[dataset['year'] < year]['playoff']\n",
    "\n",
    "    X_test = dataset[dataset['year'] == year].drop(columns=['playoff'])\n",
    "    y_test = dataset[dataset['year'] == year]['playoff']\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    svm_model = SVC(random_state=42)\n",
    "\n",
    "    svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_pred_svm = svm_model.predict(X_test_scaled)\n",
    "\n",
    "    accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "    print(f\"Support Vector Machine Accuracy: {accuracy_svm:.2f}\")\n",
    "\n",
    "    print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model(original_teams, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Selection dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model(feature_selection_result, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature engineering dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model(feature_engineering_result, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model(feature_engineering_result2, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_model(dataset, year, n_neighbors=3):\n",
    "    # Separate the training and testing sets\n",
    "    X_train = dataset[dataset['year'] < year].drop(columns=['playoff'])\n",
    "    y_train = dataset[dataset['year'] < year]['playoff']\n",
    "\n",
    "    X_test = dataset[dataset['year'] == year].drop(columns=['playoff'])\n",
    "    y_test = dataset[dataset['year'] == year]['playoff']\n",
    "\n",
    "    # Create and train the KNN model\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "    # Evaluate and print the model performance\n",
    "    accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "    print(f\"KNN Accuracy: {accuracy_knn:.2f}\")\n",
    "\n",
    "    print(classification_report(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model(original_teams, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Selection dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model(feature_selection_result, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature engineering dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model(feature_engineering_result, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model(feature_engineering_result2, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
